spring:
  application:
    name: aod-crawler

  docker:
    compose:
      enabled: false

  datasource:
    url: jdbc:postgresql://${POSTGRES_HOST:localhost}:${POSTGRES_PORT:5432}/${POSTGRES_DB:postgres}
    username: ${POSTGRES_USER:postgres}
    password: ${POSTGRES_PASSWORD:password}
    driver-class-name: org.postgresql.Driver
    hikari:
      maximum-pool-size: 5   # ğŸš€ 20 â†’ 5 (EC2 t3.small ìµœì í™”)
      minimum-idle: 2        # ğŸš€ 5 â†’ 2
      connection-timeout: 30000
      idle-timeout: 600000
      max-lifetime: 1800000
      leak-detection-threshold: 60000

  jpa:
    hibernate:
      ddl-auto: ${DDL_AUTO:create}  # Job Queue í…Œì´ë¸” ìë™ ìƒì„±/ìˆ˜ì •
    show-sql: false
    properties:
      hibernate:
        format_sql: true
        dialect: org.hibernate.dialect.PostgreSQLDialect
        default_schema: public
        jdbc:
          batch_size: 50
          batch_versioned_data: true
          use_streams_for_binary: true
        order_inserts: true
        order_updates: true
        default_batch_fetch_size: 50
        query:
          plan_cache_max_size: 2048
          plan_parameter_metadata_max_size: 128

  jackson:
    serialization:
      write-dates-as-timestamps: false
    deserialization:
      fail-on-unknown-properties: false

  cache:
    type: simple
    cache-names: traditional-recommendations,llm-recommendations

# ìŠ¤ì¼€ì¤„ë§ ì„¤ì •
scheduling:
  enabled: true

# ë¡œê¹… ì„¤ì •
logging:
  level:
    root: INFO
    com.example.crawler: DEBUG
    com.example.crawler.ingest: INFO
    com.example.crawler.service: INFO
    org.hibernate.SQL: WARN
    org.springframework.web: INFO
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
  file:
    name: logs/crawler.log      # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
    max-size: 100MB              # íŒŒì¼ ìµœëŒ€ í¬ê¸° (100MB ì´ˆê³¼ ì‹œ ë¡œí…Œì´ì…˜)
    max-history: 30              # 30ì¼ì¹˜ ë¡œê·¸ íŒŒì¼ ë³´ê´€
    total-size-cap: 3GB          # ì „ì²´ ë¡œê·¸ íŒŒì¼ ìµœëŒ€ ìš©ëŸ‰

# ëª¨ë‹ˆí„°ë§ ì„¤ì •
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus,threaddump
  endpoint:
    health:
      show-details: always
      probes:
        enabled: true
  metrics:
    export:
      prometheus:
        enabled: true
    distribution:
      percentiles-histogram:
        http:
          server:
            requests: true
    tags:
      application: ${spring.application.name}
      environment: ${spring.profiles.active:local}
    enable:
      jvm: true
      process: true
      system: true
      tomcat: true
      logback: true
      executor: true
  info:
    env:
      enabled: true

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì •ë³´
info:
  app:
    name: AOD Crawler
    description: Content Aggregation & Crawling System
    version: 1.0.0

# Sentry (ì—ëŸ¬ ì¶”ì )
sentry:
  dsn: ${SENTRY_DSN}
  environment: ${spring.profiles.active:local}
  traces-sample-rate: 0.1
  logging:
    minimum-event-level: error
    minimum-breadcrumb-level: info
  send-default-pii: true
  enable-tracing: true
  tags:
    application: ${spring.application.name}
    version: ${info.app.version:1.0.0}
  ignored-exceptions-for-type: org.springframework.web.HttpRequestMethodNotSupportedException

# ì„œë²„ ì„¤ì •
server:
  port: 8081  # API ì„œë²„ì™€ ë¶„ë¦¬ (8080ê³¼ ë‹¤ë¥¸ í¬íŠ¸)
  shutdown: graceful
  tomcat:
    threads:
      max: 20      # ğŸš€ 200 â†’ 20 (EC2 t3.small ìµœì í™”)
      min-spare: 2  # ğŸš€ 10 â†’ 2
    max-connections: 1000    # ğŸš€ 10000 â†’ 1000
    accept-count: 50         # ğŸš€ 100 â†’ 50
    connection-timeout: 20000

# í¬ë¡¤ëŸ¬ ì „ìš© ì„¤ì •
crawler:
  steam:
    api-key: ${STEAM_API_KEY}
    rate-limit:
      requests-per-second: 1
  tmdb:
    api-key: ${TMDB_API_KEY}
    language: ko-KR
  batch:
    size: 50              # ğŸš€ 100 â†’ 50 (EC2 t3.small ìµœì í™”)
    transform-interval: 900000  # ğŸš€ 10ë¶„ â†’ 15ë¶„ (600000 â†’ 900000)
  
  # ğŸš€ ë¦¬ì†ŒìŠ¤ ì œì–´ (EC2 t3.small ì•ˆì „ í•œê³„)
  # CrawlJobConsumerì—ì„œ í•˜ë“œì½”ë”©ë¨:
  # - MAX_CONCURRENT_JOBS = 10  (ì „ì—­ ìµœëŒ€ ë™ì‹œ ì²˜ë¦¬)
  # - MAX_SELENIUM_JOBS = 2     (Selenium ìµœëŒ€ ë™ì‹œ ì²˜ë¦¬)
  # Phase 2ì—ì„œ í™˜ê²½ë³€ìˆ˜ë¡œ ë³€ê²½ ì˜ˆì •

# API Keys (í™˜ê²½ë³€ìˆ˜ë¡œ ì£¼ì… í•„ìš”)
tmdb:
  api:
    key: ${TMDB_API_KEY}

steam:
  api:
    key: ${STEAM_API_KEY}

openai:
  api:
    key: ${OPENAI_API_KEY}
    url: https://api.openai.com/v1/chat/completions

# ì¶”ì²œ ì‹œìŠ¤í…œ ì„¤ì •
recommendation:
  traditional:
    max-items-per-category: 10
  llm:
    max-tokens: 1500
    temperature: 0.7
    model: gpt-3.5-turbo

